{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1c8f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "import preprocess_csv as preprocess\n",
    "from textrank.textrank import KeywordSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d696b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/topic2/trust_robot.csv')\n",
    "papers = preprocess.extract_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbf83e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    '''\n",
    "    apply tokenizer\n",
    "    '''\n",
    "    cachedStopWords = stopwords.words(\"english\")\n",
    "    RegTok = RegexpTokenizer(\"[\\w']{3,}\")\n",
    "    english_stops = set(stopwords.words('english'))\n",
    "    tokens = RegTok.tokenize(text.lower())\n",
    "    # stopwords 제외\n",
    "    words = [word for word in tokens if (word not in english_stops) and len(word) > 2]\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    word_token = [stemmer.stem(i) for i in words]\n",
    "    \n",
    "    return word_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "102689b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token2word(papers):\n",
    "    '''\n",
    "    return the list of dictionary (key: stemmized token, value: original word)\n",
    "    '''\n",
    "    word_token_list = []\n",
    "    for text in papers:\n",
    "        cachedStopWords = stopwords.words(\"english\")\n",
    "        RegTok = RegexpTokenizer(\"[\\w']{3,}\")\n",
    "        english_stops = set(stopwords.words('english'))\n",
    "        tokens = RegTok.tokenize(text.lower())\n",
    "        # stopwords 제외\n",
    "         # stopwords 제외\n",
    "        words = [word for word in tokens if (word not in english_stops) and len(word) > 2]\n",
    "\n",
    "        stemmer = PorterStemmer()\n",
    "        word_token_dict = [{stemmer.stem(word):word} for word in words]\n",
    "        word_token_list.append(word_token_dict)\n",
    "        \n",
    "    # flatten\n",
    "    word_token_list = list(itertools.chain(*word_token_list))\n",
    "    \n",
    "    word_token_dict = dict()\n",
    "    for element in word_token_list:\n",
    "        word_token_dict = merge_dicts(merged, element)\n",
    "    \n",
    "    return word_token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "689573c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dicts(a, b):\n",
    "    c = a.copy()  # a 변수를 c에 copy 한 후,\n",
    "    c.update(b)   # c를 update하여 반환\n",
    "\n",
    "    return c     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e9060e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_token_dict = get_token2word(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70719533",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = KeywordSummarizer(tokenize=tokenizer, min_count=2, min_cooccurrence=1)\n",
    "textrank_result = summarizer.summarize(papers, topk=30)\n",
    "\n",
    "keywords = [element[0] for element in textrank_result]\n",
    "lemma_keyword = [lemmatizer.lemmatize(word_token_dict[keyword], pos='v') for keyword in keywords]\n",
    "ranks = [element[1] for element in textrank_result]\n",
    "\n",
    "textrank_df = pd.DataFrame()\n",
    "textrank_df['keyword'] = lemma_keywords; textrank_df['rank'] = ranks\n",
    "textrak_df.to_csv('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
