{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d976157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "import preprocess_csv as preprocess\n",
    "from textrank.textrank import KeywordSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e879980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/topic2/trust_robot.csv')\n",
    "papers = preprocess.extract_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e18ed2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    '''\n",
    "    apply tokenizer\n",
    "    '''\n",
    "    cachedStopWords = stopwords.words(\"english\")\n",
    "    RegTok = RegexpTokenizer(\"[\\w']{3,}\")\n",
    "    english_stops = set(stopwords.words('english'))\n",
    "    tokens = RegTok.tokenize(text.lower())\n",
    "    # stopwords 제외\n",
    "    words = [word for word in tokens if (word not in english_stops) and len(word) > 2]\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    word_token = [stemmer.stem(i) for i in words]\n",
    "    \n",
    "    return word_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef0398ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(text):\n",
    "    '''\n",
    "    get tokenizer\n",
    "    '''\n",
    "    cachedStopWords = stopwords.words(\"english\")\n",
    "    RegTok = RegexpTokenizer(\"[\\w']{3,}\")\n",
    "    english_stops = set(stopwords.words('english'))\n",
    "    tokens = RegTok.tokenize(text.lower())\n",
    "    # stopwords 제외\n",
    "     # stopwords 제외\n",
    "    words = [word for word in tokens if (word not in english_stops) and len(word) > 2]\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    word_token_dict = [{word:stemmer.stem(i)} for word in words]\n",
    "    \n",
    "    return word_token_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f95504a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = KeywordSummarizer(tokenize=tokenizer, min_count=2, min_cooccurrence=1)\n",
    "textrank_result = summarizer.summarize(papers, topk=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6186836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [element[0] for element in textrank_result]\n",
    "ranks = [element[1] for element in textrank_result]\n",
    "textrank_df = pd.DataFrame()\n",
    "textrank_df['keyword'] = keywords; textrank_df['rank'] = ranks\n",
    "textrak_df.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8157409b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>robot</td>\n",
       "      <td>88.184419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patient</td>\n",
       "      <td>64.930349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>use</td>\n",
       "      <td>53.617676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>studi</td>\n",
       "      <td>44.220035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surgeri</td>\n",
       "      <td>43.147857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>result</td>\n",
       "      <td>34.289463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>outcom</td>\n",
       "      <td>32.679889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>compar</td>\n",
       "      <td>29.475188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>surgic</td>\n",
       "      <td>26.775768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>perform</td>\n",
       "      <td>26.537537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>method</td>\n",
       "      <td>24.979993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>assist</td>\n",
       "      <td>24.798964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>group</td>\n",
       "      <td>23.888395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rate</td>\n",
       "      <td>23.884813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>time</td>\n",
       "      <td>23.793869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>includ</td>\n",
       "      <td>22.275060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>differ</td>\n",
       "      <td>21.966742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>oper</td>\n",
       "      <td>21.571370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>data</td>\n",
       "      <td>19.358237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>conclus</td>\n",
       "      <td>19.192320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>treatment</td>\n",
       "      <td>19.106016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>laparoscop</td>\n",
       "      <td>18.558275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>evid</td>\n",
       "      <td>17.854304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>effect</td>\n",
       "      <td>17.854178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>human</td>\n",
       "      <td>17.728222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cancer</td>\n",
       "      <td>17.688115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>control</td>\n",
       "      <td>17.524762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>train</td>\n",
       "      <td>17.449530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>assess</td>\n",
       "      <td>17.012586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>approach</td>\n",
       "      <td>16.962812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       keyword       rank\n",
       "0        robot  88.184419\n",
       "1      patient  64.930349\n",
       "2          use  53.617676\n",
       "3        studi  44.220035\n",
       "4      surgeri  43.147857\n",
       "5       result  34.289463\n",
       "6       outcom  32.679889\n",
       "7       compar  29.475188\n",
       "8       surgic  26.775768\n",
       "9      perform  26.537537\n",
       "10      method  24.979993\n",
       "11      assist  24.798964\n",
       "12       group  23.888395\n",
       "13        rate  23.884813\n",
       "14        time  23.793869\n",
       "15      includ  22.275060\n",
       "16      differ  21.966742\n",
       "17        oper  21.571370\n",
       "18        data  19.358237\n",
       "19     conclus  19.192320\n",
       "20   treatment  19.106016\n",
       "21  laparoscop  18.558275\n",
       "22        evid  17.854304\n",
       "23      effect  17.854178\n",
       "24       human  17.728222\n",
       "25      cancer  17.688115\n",
       "26     control  17.524762\n",
       "27       train  17.449530\n",
       "28      assess  17.012586\n",
       "29    approach  16.962812"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639d82c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
